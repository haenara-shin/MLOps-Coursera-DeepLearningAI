WEBVTT

1
00:00:00.000 --> 00:00:04.170
Let's discuss schema
environments.

2
00:00:04.170 --> 00:00:07.185
Your business and
data will evolve

3
00:00:07.185 --> 00:00:10.410
throughout the lifetime of
your production pipeline.

4
00:00:10.410 --> 00:00:13.590
It's often the case that
as your data evolves,

5
00:00:13.590 --> 00:00:16.230
your schema evolves also.

6
00:00:16.230 --> 00:00:18.420
As you're developing your code

7
00:00:18.420 --> 00:00:21.000
to handle changes in your schema,

8
00:00:21.000 --> 00:00:23.130
you may have multiple versions of

9
00:00:23.130 --> 00:00:26.235
your schema all active
at the same time.

10
00:00:26.235 --> 00:00:29.485
You may have one schema
being used for development,

11
00:00:29.485 --> 00:00:31.385
one currently in test,

12
00:00:31.385 --> 00:00:33.775
and another currently
in production.

13
00:00:33.775 --> 00:00:36.665
Having version control
for your schemas,

14
00:00:36.665 --> 00:00:38.960
just like you do for your code,

15
00:00:38.960 --> 00:00:41.120
helps make this manageable.

16
00:00:41.120 --> 00:00:43.280
In some cases, you may

17
00:00:43.280 --> 00:00:45.380
need to have different
schemas to support

18
00:00:45.380 --> 00:00:47.330
multiple training and deployment

19
00:00:47.330 --> 00:00:50.650
scenarios for different
data environments.

20
00:00:50.650 --> 00:00:52.760
For example, you may want to use

21
00:00:52.760 --> 00:00:55.070
the same model on a server and in

22
00:00:55.070 --> 00:00:58.250
a mobile application
but imagine that

23
00:00:58.250 --> 00:00:59.630
a particular feature is

24
00:00:59.630 --> 00:01:01.850
different in those
two environments.

25
00:01:01.850 --> 00:01:03.140
Maybe in one case it's

26
00:01:03.140 --> 00:01:05.915
an integer and the other
case it's a float.

27
00:01:05.915 --> 00:01:08.465
You need to have a
different schema for

28
00:01:08.465 --> 00:01:11.525
each to reflect the
difference in the data.

29
00:01:11.525 --> 00:01:14.585
Along with that, your
data's evolving.

30
00:01:14.585 --> 00:01:18.785
Potentially, in all your different
data environments at once.

31
00:01:18.785 --> 00:01:21.620
But at the same time you
also needed to check

32
00:01:21.620 --> 00:01:24.350
your data for problems
or anomalies,

33
00:01:24.350 --> 00:01:29.585
and schemas are a key part
of checking for anomalies.

34
00:01:29.585 --> 00:01:31.820
Let's look at an example of how

35
00:01:31.820 --> 00:01:34.160
a schema can help
you detect errors in

36
00:01:34.160 --> 00:01:36.710
your serving request data and why

37
00:01:36.710 --> 00:01:39.835
multiple versions of your
schema are important.

38
00:01:39.835 --> 00:01:43.940
We'll start by inferring the
serving schema and we'll

39
00:01:43.940 --> 00:01:48.875
use TensorFlow Data Validation
or TFTV to do that.

40
00:01:48.875 --> 00:01:51.020
Then we're going to generate

41
00:01:51.020 --> 00:01:54.260
statistics for the
serving dataset.

42
00:01:54.260 --> 00:01:56.750
Then we'll use TFTV to

43
00:01:56.750 --> 00:01:59.510
find if there are any
problems with this data

44
00:01:59.510 --> 00:02:04.890
and visualize the result in
a notebook. Look at that.

45
00:02:04.890 --> 00:02:07.040
TFTV reports back that

46
00:02:07.040 --> 00:02:09.910
there are anomalies
in the serving data.

47
00:02:09.910 --> 00:02:12.050
Since this is a dataset

48
00:02:12.050 --> 00:02:14.105
that contains
prediction requests,

49
00:02:14.105 --> 00:02:16.550
that's actually not surprising.

50
00:02:16.550 --> 00:02:19.955
The label which is
cover type is missing,

51
00:02:19.955 --> 00:02:21.990
but the schema is telling TFTV

52
00:02:21.990 --> 00:02:24.600
that the cover type
feature is required.

53
00:02:24.600 --> 00:02:28.025
So it's flagging
this as an anomaly.

54
00:02:28.025 --> 00:02:30.175
How do we fix this problem?

55
00:02:30.175 --> 00:02:32.420
In scenarios where
you need to maintain

56
00:02:32.420 --> 00:02:35.465
multiple types of
the same schemas,

57
00:02:35.465 --> 00:02:38.900
you often need to keep
the schema environment.

58
00:02:38.900 --> 00:02:41.150
This is most commonly true of

59
00:02:41.150 --> 00:02:44.230
the difference between
training and serving data.

60
00:02:44.230 --> 00:02:46.865
You can choose to
customize your schema

61
00:02:46.865 --> 00:02:49.670
based on the situation
you're going to handle.

62
00:02:49.670 --> 00:02:52.055
For example, in this case,

63
00:02:52.055 --> 00:02:54.860
the setup is to
maintain two schemas.

64
00:02:54.860 --> 00:02:56.960
One for training data,

65
00:02:56.960 --> 00:02:59.900
where the label is
required and the other for

66
00:02:59.900 --> 00:03:03.470
serving where we know we
won't have the label.

67
00:03:03.470 --> 00:03:06.560
The code for multiple
schema environments

68
00:03:06.560 --> 00:03:08.150
is fairly straightforward.

69
00:03:08.150 --> 00:03:09.860
In our existing environment,

70
00:03:09.860 --> 00:03:12.395
we already have a
schema for training.

71
00:03:12.395 --> 00:03:15.200
We then create two
named environments

72
00:03:15.200 --> 00:03:17.560
called training and serving.

73
00:03:17.560 --> 00:03:20.225
We modify our serving environment

74
00:03:20.225 --> 00:03:22.820
by removing the
cover type feature.

75
00:03:22.820 --> 00:03:24.830
Since we know that in serving,

76
00:03:24.830 --> 00:03:27.725
we won't have that
in our feature set.

77
00:03:27.725 --> 00:03:31.250
Lastly, the code sets up
the serving environment

78
00:03:31.250 --> 00:03:34.760
and uses it to validate
the serving data.

79
00:03:34.760 --> 00:03:38.450
Now, there are no anomalies
found since we're using

80
00:03:38.450 --> 00:03:42.110
the correct schema for
our data. Let's review.

81
00:03:42.110 --> 00:03:45.740
First we discussed how to
iteratively update and fine

82
00:03:45.740 --> 00:03:49.805
tune your schema to
adapt to evolving data.

83
00:03:49.805 --> 00:03:52.730
Then we focused on
reliability and

84
00:03:52.730 --> 00:03:56.945
scalability during the
evolution cycle of data.

85
00:03:56.945 --> 00:03:59.870
Then you implemented
schema environments

86
00:03:59.870 --> 00:04:03.540
to deal with anomalies
in your serving data.