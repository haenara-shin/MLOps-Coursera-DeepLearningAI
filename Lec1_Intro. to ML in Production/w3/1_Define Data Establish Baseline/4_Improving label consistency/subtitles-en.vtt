WEBVTT

1
00:00:00.000 --> 00:00:02.400
Let's take a look at
some ways to improve

2
00:00:02.400 --> 00:00:04.730
the consistency of your labels.

3
00:00:04.730 --> 00:00:08.020
Here's a general
process you can use.

4
00:00:08.020 --> 00:00:12.395
If you are worried about
labels being inconsistent,

5
00:00:12.395 --> 00:00:14.420
find a few examples and have

6
00:00:14.420 --> 00:00:17.495
multiple labelers label
the same example.

7
00:00:17.495 --> 00:00:20.150
In some cases you can also have

8
00:00:20.150 --> 00:00:22.955
the same labeler
label an example,

9
00:00:22.955 --> 00:00:25.310
wait a while until
they have hopefully

10
00:00:25.310 --> 00:00:28.610
forgotten or technical
term is wash out,

11
00:00:28.610 --> 00:00:31.640
but have them take a break
and then come back and

12
00:00:31.640 --> 00:00:33.110
re-label it and see if they're

13
00:00:33.110 --> 00:00:35.370
even consistent with themselves.

14
00:00:35.370 --> 00:00:38.305
When you find that
there's disagreements,

15
00:00:38.305 --> 00:00:42.030
have the people
responsible for labeling,

16
00:00:42.030 --> 00:00:44.015
this could be the
machine label engineer,

17
00:00:44.015 --> 00:00:46.345
it could be the
subject matter expert,

18
00:00:46.345 --> 00:00:49.210
such as the manufacturing
expert that is responsible

19
00:00:49.210 --> 00:00:52.120
for labeling what is a stretch
and what isn't a stretch,

20
00:00:52.120 --> 00:00:54.940
and/or the dedicated labelers,

21
00:00:54.940 --> 00:00:57.670
discuss together what
they think should

22
00:00:57.670 --> 00:01:01.270
be a more consistent
definition of a label y,

23
00:01:01.270 --> 00:01:05.305
and try to have them
reach an agreement.

24
00:01:05.305 --> 00:01:10.495
Ideally, also document and
write down that agreement,

25
00:01:10.495 --> 00:01:13.375
and this definition of y

26
00:01:13.375 --> 00:01:16.790
can then become an updated set of

27
00:01:16.790 --> 00:01:19.625
labeling instructions
that they can go back to

28
00:01:19.625 --> 00:01:24.220
label new data or to
relabel old data.

29
00:01:24.220 --> 00:01:28.520
During this discussion, in
some cases the labelers will

30
00:01:28.520 --> 00:01:30.530
come back and say
they don't think

31
00:01:30.530 --> 00:01:32.885
the input x has
enough information.

32
00:01:32.885 --> 00:01:34.295
If that's the case,

33
00:01:34.295 --> 00:01:37.510
consider changing the input x.

34
00:01:37.510 --> 00:01:41.480
For example, when we saw
the pictures of phones,

35
00:01:41.480 --> 00:01:42.970
they were was so dark that we

36
00:01:42.970 --> 00:01:44.955
couldn't even tell
what was going on,

37
00:01:44.955 --> 00:01:47.215
that was a sign that we should

38
00:01:47.215 --> 00:01:49.740
consider increasing
the illumination,

39
00:01:49.740 --> 00:01:52.305
the lighting with which
the pictures were taken.

40
00:01:52.305 --> 00:01:55.269
But of course, I know this
isn't always possible,

41
00:01:55.269 --> 00:01:57.115
but sometimes this
can be a big help.

42
00:01:57.115 --> 00:02:00.310
Then all this is an
iterative process.

43
00:02:00.310 --> 00:02:02.260
So after improve x or

44
00:02:02.260 --> 00:02:04.685
after improving the
label instructions,

45
00:02:04.685 --> 00:02:07.965
you will ask the team
to label more data.

46
00:02:07.965 --> 00:02:11.350
If you think there are
still disagreements,

47
00:02:11.350 --> 00:02:13.990
then repeat the whole process of

48
00:02:13.990 --> 00:02:17.035
having multiple labelers
label the same example,

49
00:02:17.035 --> 00:02:19.505
major disagreement and so on.

50
00:02:19.505 --> 00:02:21.290
Let's look at some examples.

51
00:02:21.290 --> 00:02:24.520
One common outcome of
this type of exercise

52
00:02:24.520 --> 00:02:28.405
is to standardize the
definition of labels.

53
00:02:28.405 --> 00:02:31.060
Between these ways of labeling

54
00:02:31.060 --> 00:02:33.955
the audio clip you heard
on the earlier video,

55
00:02:33.955 --> 00:02:36.190
perhaps the labelers
will standardize

56
00:02:36.190 --> 00:02:39.190
on this as the convention,

57
00:02:39.190 --> 00:02:41.115
or maybe they'll
pick a different one

58
00:02:41.115 --> 00:02:42.700
and that could be okay too.

59
00:02:42.700 --> 00:02:45.945
But at least this makes
the data more consistent.

60
00:02:45.945 --> 00:02:49.300
Another common decision
that I've seen come out

61
00:02:49.300 --> 00:02:52.855
of a process like this
is merging classes.

62
00:02:52.855 --> 00:02:56.560
If in your labeling
guidelines you asked labelers

63
00:02:56.560 --> 00:02:59.890
to label deep scratches on
the surface of the phone,

64
00:02:59.890 --> 00:03:03.035
as well as shallow scratches
on the surface of the phone,

65
00:03:03.035 --> 00:03:05.710
but if the definition
between what constitutes

66
00:03:05.710 --> 00:03:11.189
a deep scratch versus
a shallow scratch,

67
00:03:11.189 --> 00:03:14.565
barely visible here
I know, is unclear,

68
00:03:14.565 --> 00:03:17.940
then you end up with
labelers very inconsistently

69
00:03:17.940 --> 00:03:21.930
labeling things as deep
versus shallow scratches.

70
00:03:21.930 --> 00:03:24.270
Sometimes the factory
does really need to

71
00:03:24.270 --> 00:03:28.200
distinguish between deep
versus shallow scratches.

72
00:03:28.200 --> 00:03:30.420
Sometimes factories
need to do this to

73
00:03:30.420 --> 00:03:32.875
figure out what was the
cause of the defect.

74
00:03:32.875 --> 00:03:36.270
But sometimes I found that you

75
00:03:36.270 --> 00:03:37.470
don't really need to

76
00:03:37.470 --> 00:03:39.780
distinguish between
these two classes,

77
00:03:39.780 --> 00:03:41.940
and you can instead merge

78
00:03:41.940 --> 00:03:45.885
the two classes into
a single class, say,

79
00:03:45.885 --> 00:03:49.260
the scratch class, and
this gets rid of all of

80
00:03:49.260 --> 00:03:51.840
the inconsistencies
with different

81
00:03:51.840 --> 00:03:55.095
labelers labeling the same
thing deep versus shallow.

82
00:03:55.095 --> 00:03:58.080
Merging classes isn't
always applicable,

83
00:03:58.080 --> 00:03:59.160
but when it is,

84
00:03:59.160 --> 00:04:01.980
it simplifies the task for
the learning algorithm.

85
00:04:01.980 --> 00:04:05.100
One of the technique I've used
is to create a new class,

86
00:04:05.100 --> 00:04:09.840
or create a new label
to capture uncertainty.

87
00:04:09.840 --> 00:04:14.330
For example, let's say you
asked labelers to label

88
00:04:14.330 --> 00:04:16.085
phones as defective or not

89
00:04:16.085 --> 00:04:18.710
based on the length
of the scratch.

90
00:04:18.710 --> 00:04:20.810
Here's a sequence of smartphones

91
00:04:20.810 --> 00:04:23.155
with larger and larger scratches.

92
00:04:23.155 --> 00:04:25.220
Not sure if you can see
these on your display,

93
00:04:25.220 --> 00:04:28.120
but let me just make them a
little bit more visible here.

94
00:04:28.120 --> 00:04:29.960
I know that all of these are

95
00:04:29.960 --> 00:04:31.280
really large scratches if

96
00:04:31.280 --> 00:04:32.800
this is a real phone
you're buying.

97
00:04:32.800 --> 00:04:35.035
This is just for
illustrative purposes.

98
00:04:35.035 --> 00:04:38.825
Maybe everyone agrees that the
giant scratch is a defect,

99
00:04:38.825 --> 00:04:41.315
a tiny scratch is not a defect,

100
00:04:41.315 --> 00:04:43.830
but they don't agree
on what's in between.

101
00:04:43.830 --> 00:04:46.880
If it was possible to
get them to agree,

102
00:04:46.880 --> 00:04:51.525
then that would be one way
to reduce label ambiguity.

103
00:04:51.525 --> 00:04:53.600
But if that turns
out to be difficult,

104
00:04:53.600 --> 00:04:56.225
then here's another option;

105
00:04:56.225 --> 00:04:58.130
which is to create

106
00:04:58.130 --> 00:05:01.400
a new class where you
now have three labels.

107
00:05:01.400 --> 00:05:03.925
You can say, it's
clearly not a defect,

108
00:05:03.925 --> 00:05:05.395
or clearly a defect,

109
00:05:05.395 --> 00:05:08.210
or just acknowledge
there's some examples are

110
00:05:08.210 --> 00:05:12.205
ambiguous and put them in
a new borderline class.

111
00:05:12.205 --> 00:05:14.900
If it becomes easier
to come up with

112
00:05:14.900 --> 00:05:17.900
consistent instructions for
this three class problem,

113
00:05:17.900 --> 00:05:20.990
because maybe some examples
are genuinely borderline,

114
00:05:20.990 --> 00:05:26.060
then that could potentially
improve labeling consistency.

115
00:05:26.060 --> 00:05:28.220
Let me use speech illustration

116
00:05:28.220 --> 00:05:31.320
to illustrate this further.

117
00:05:31.790 --> 00:05:34.260
Given this audio clip,

118
00:05:34.260 --> 00:05:39.630
[inaudible] I really can't
tell what they said.

119
00:05:39.630 --> 00:05:43.480
[inaudible] If you were

120
00:05:43.480 --> 00:05:46.060
to force everyone
to transcribe it,

121
00:05:46.060 --> 00:05:49.110
some labelers would
transcribe, "Nearly go."

122
00:05:49.110 --> 00:05:50.550
Some maybe they'll say,

123
00:05:50.550 --> 00:05:54.460
"Nearest grocery," and it's
very difficult to get to

124
00:05:54.460 --> 00:05:56.200
consistency because

125
00:05:56.200 --> 00:05:59.840
the audio clip is
genuinely ambiguous.

126
00:05:59.840 --> 00:06:02.250
To improve labeling consistency,

127
00:06:02.250 --> 00:06:04.840
it may be better to
create a new tag,

128
00:06:04.840 --> 00:06:06.580
the unintelligible tag, and

129
00:06:06.580 --> 00:06:08.545
just ask everyone to label this

130
00:06:08.545 --> 00:06:13.370
as nearest [inaudible]
unintelligible.

131
00:06:14.090 --> 00:06:16.300
This can result in

132
00:06:16.300 --> 00:06:19.480
more consistent labels than
if we were to ask everyone to

133
00:06:19.480 --> 00:06:24.435
guess what they heard when
it really is unintelligible.

134
00:06:24.435 --> 00:06:28.660
Let me wrap up with some
suggestions for working with

135
00:06:28.660 --> 00:06:33.780
small versus big datasets to
improve label consistency.

136
00:06:33.780 --> 00:06:36.610
We've just been talking
about unstructured data or

137
00:06:36.610 --> 00:06:39.880
problems where we can count
on people to label the data.

138
00:06:39.880 --> 00:06:41.380
For small datasets there's

139
00:06:41.380 --> 00:06:43.690
usually a small
number of labelers.

140
00:06:43.690 --> 00:06:46.105
So when you find
an inconsistency,

141
00:06:46.105 --> 00:06:48.400
you can ask the labelers
to sit down and

142
00:06:48.400 --> 00:06:51.335
discuss a specific image
or a specific audio clip,

143
00:06:51.335 --> 00:06:54.240
and try to drive to an agreement.

144
00:06:54.240 --> 00:06:57.550
For big datasets,
it would be more

145
00:06:57.550 --> 00:06:59.260
common to try to get to

146
00:06:59.260 --> 00:07:01.960
consistent definition
with a small group,

147
00:07:01.960 --> 00:07:04.510
and then send the
labeling instructions

148
00:07:04.510 --> 00:07:06.580
to a larger group of labelers.

149
00:07:06.580 --> 00:07:09.800
One other technique
that is commonly used,

150
00:07:09.800 --> 00:07:12.220
but I think overused
in my opinion,

151
00:07:12.220 --> 00:07:13.720
is that you can have

152
00:07:13.720 --> 00:07:17.170
multiple labelers
label every example

153
00:07:17.170 --> 00:07:18.700
and then let them vote.

154
00:07:18.700 --> 00:07:22.570
Voting is sometimes called
consensus labeling,

155
00:07:22.570 --> 00:07:24.840
in order to increase accuracy.

156
00:07:24.840 --> 00:07:28.355
I find that this type of
voting mechanism technique,

157
00:07:28.355 --> 00:07:30.100
it can work, but it's

158
00:07:30.100 --> 00:07:33.610
probably over used in
machine learning today.

159
00:07:33.610 --> 00:07:36.520
Where what I've
seen a lot of teams

160
00:07:36.520 --> 00:07:39.880
do is have inconsistent
labeling instructions,

161
00:07:39.880 --> 00:07:42.805
and then try to have a lot
of labelers and then voting,

162
00:07:42.805 --> 00:07:44.920
to try to make it
more consistent.

163
00:07:44.920 --> 00:07:47.080
But before resorting to this,

164
00:07:47.080 --> 00:07:48.310
which I do use,

165
00:07:48.310 --> 00:07:49.945
but more of a last resort,

166
00:07:49.945 --> 00:07:51.970
I would use the first,

167
00:07:51.970 --> 00:07:56.530
try to get to more consistent
label definitions,

168
00:07:56.530 --> 00:07:59.620
to try to make the
individual labelers choices

169
00:07:59.620 --> 00:08:01.780
less noisy in the first place,

170
00:08:01.780 --> 00:08:04.180
rather than take a lot
of noisy data and then

171
00:08:04.180 --> 00:08:06.955
try to use voting to
reduce the noise.

172
00:08:06.955 --> 00:08:09.730
I hope that the tools you
just learnt for improving

173
00:08:09.730 --> 00:08:12.010
label consistency
will help you to get

174
00:08:12.010 --> 00:08:14.860
better data for your
machine learning task.

175
00:08:14.860 --> 00:08:17.950
One of the gaps I see in
the machine learning world

176
00:08:17.950 --> 00:08:20.930
today is that there's
still a lack of tools,

177
00:08:20.930 --> 00:08:22.750
and there are also
machine learning ops

178
00:08:22.750 --> 00:08:24.940
tools for helping teams

179
00:08:24.940 --> 00:08:26.230
to carry out this type of

180
00:08:26.230 --> 00:08:29.130
process more consistently
and repeatedly.

181
00:08:29.130 --> 00:08:30.790
It's not us trying to

182
00:08:30.790 --> 00:08:33.160
figure this out in
the Jupyter Notebook,

183
00:08:33.160 --> 00:08:35.050
but instead to have tools help

184
00:08:35.050 --> 00:08:37.460
us to detect when labels are

185
00:08:37.460 --> 00:08:39.800
inconsistent and
to help facilitate

186
00:08:39.800 --> 00:08:43.805
the process in improving
the quality of the data.

187
00:08:43.805 --> 00:08:46.360
This is something I look
forward to hopefully

188
00:08:46.360 --> 00:08:50.075
our community working
on and developing.

189
00:08:50.075 --> 00:08:53.070
In terms of improving
label quality,

190
00:08:53.070 --> 00:08:55.910
one of the questions
that often comes up is:

191
00:08:55.910 --> 00:08:59.040
What is human level
performance on the task?

192
00:08:59.040 --> 00:09:00.930
I find human level
performance to be

193
00:09:00.930 --> 00:09:03.755
important and sometimes
misused concept.

194
00:09:03.755 --> 00:09:07.450
Let's take a deeper look
at this in the next video.