WEBVTT

1
00:00:00.340 --> 00:00:04.249
Many AI systems are not just a single
machine learning model running

2
00:00:04.249 --> 00:00:08.660
a prediction service, but instead
involves a pipeline of multiple steps.

3
00:00:08.660 --> 00:00:11.111
So what are machine learning pipelines and

4
00:00:11.111 --> 00:00:13.780
how do you build monitoring systems for
that?

5
00:00:13.780 --> 00:00:16.440
Let's learn about that in this video.

6
00:00:16.440 --> 00:00:21.263
Let's continue with our speech
recognition example, you've seen how

7
00:00:21.263 --> 00:00:26.580
a speech recognition system may take as
input audio and I'll put a transcript.

8
00:00:26.580 --> 00:00:31.281
The way that speech recognition is
typically implemented on mobile apps is

9
00:00:31.281 --> 00:00:32.257
not like this.

10
00:00:32.257 --> 00:00:38.061
But instead is a slightly
more complex pipeline

11
00:00:38.061 --> 00:00:43.720
where the audio is fed to
a module called a VAD or

12
00:00:43.720 --> 00:00:48.656
a voice activity detection module whose

13
00:00:48.656 --> 00:00:53.318
job it is to see if anyone is speaking.

14
00:00:53.318 --> 00:00:57.897
And only if the VAD module,
the voice activity detection module,

15
00:00:57.897 --> 00:01:02.720
thinks someone is speaking, does it
then bother to pass the audio on to

16
00:01:02.720 --> 00:01:08.140
a speech recognition system whose job
it is to then generate the transcript.

17
00:01:08.140 --> 00:01:12.881
And the reason we use a VAD module
is because if the speech recognition

18
00:01:12.881 --> 00:01:14.679
system runs in the cloud,

19
00:01:14.679 --> 00:01:19.200
you don't want to stream more audio
than you have to to the cloud.

20
00:01:19.200 --> 00:01:24.233
And the reason we use a voice activity
detection or VAD module is because if,

21
00:01:24.233 --> 00:01:27.852
say your speech recognition
system runs in the cloud,

22
00:01:27.852 --> 00:01:33.140
you don't want to stream more bandwidth
than you have to to your cloud server.

23
00:01:33.140 --> 00:01:38.069
And so the voice activity detection
module looks at the long stream

24
00:01:38.069 --> 00:01:40.885
of audio on your cell phone and clips or

25
00:01:40.885 --> 00:01:45.373
shortens the audio to just a part
where someone is talking and

26
00:01:45.373 --> 00:01:50.860
streams only that to the cloud server
to perform the speech recognition.

27
00:01:50.860 --> 00:01:56.849
So this is an example of a machine
learning pipeline where there is one step

28
00:01:56.849 --> 00:02:03.540
usually done by learning algorithm as well
to decide if someone is talking or not.

29
00:02:03.540 --> 00:02:07.892
And then the second step also
done by a learning algorithm to

30
00:02:07.892 --> 00:02:10.639
generate the text transcript.

31
00:02:10.639 --> 00:02:14.933
When you have two learning algorithms,
one thus learn to detect when

32
00:02:14.933 --> 00:02:18.795
someone's talking and
one does learn to transcribe speech.

33
00:02:18.795 --> 00:02:22.494
When you have two such
modules working together,

34
00:02:22.494 --> 00:02:28.770
changes to the first module may affect the
performance of the second module as well.

35
00:02:28.770 --> 00:02:34.715
For example, let's say that because of the
way a new cell phone's microphone works,

36
00:02:34.715 --> 00:02:38.940
the VAD module ends up clipping
the audio differently.

37
00:02:38.940 --> 00:02:42.225
Maybe it leaves more silence
at the start or end or

38
00:02:42.225 --> 00:02:46.952
less silence at the start or end and
thus if the VAD's output changes,

39
00:02:46.952 --> 00:02:51.390
that will cause the speech
recognition systems input to change.

40
00:02:51.390 --> 00:02:56.140
And that could cause degraded performance
of the speech recognition system.

41
00:02:56.140 --> 00:02:59.400
Let's look at an example
involving user profiles.

42
00:02:59.400 --> 00:03:03.170
Maybe I've used the data such as
clickstream data showing what users

43
00:03:03.170 --> 00:03:04.160
are clicking on.

44
00:03:04.160 --> 00:03:08.991
And this can be used to build a user
profile that tries to capture

45
00:03:08.991 --> 00:03:12.840
key attributes or
key characteristics of a user.

46
00:03:12.840 --> 00:03:13.837
For example,

47
00:03:13.837 --> 00:03:19.327
I once built user profiles that would
try to explain many attributes of users,

48
00:03:19.327 --> 00:03:24.565
including whether or not the user seemed
to own a car because this would help

49
00:03:24.565 --> 00:03:29.827
us decide if it was worth trying to
offer car insurance office to that user.

50
00:03:29.827 --> 00:03:34.714
And so whether the user owns
a car could be yes or no or

51
00:03:34.714 --> 00:03:39.845
unknown or
maybe other final gradations than these.

52
00:03:39.845 --> 00:03:44.299
And the typical way that the user profile
is built is with a learning algorithm to

53
00:03:44.299 --> 00:03:46.438
try to predict if this user owns a car.

54
00:03:46.438 --> 00:03:51.376
This type of user profile, which can have
a very long list of predicted attributes,

55
00:03:51.376 --> 00:03:56.317
can then be fed to a recommender system,
another learning algorithm that then takes

56
00:03:56.317 --> 00:04:01.340
this understanding of the user to try
to generate product recommendations.

57
00:04:01.340 --> 00:04:05.938
Now, if something about
the clickstream data changes,

58
00:04:05.938 --> 00:04:10.920
maybe this input distribution changes,
then maybe over time

59
00:04:10.920 --> 00:04:15.321
if we lose our ability to figure
out if a user owns a car,

60
00:04:15.321 --> 00:04:20.339
then the percentage of
the unknown tag here may go up.

61
00:04:20.339 --> 00:04:24.139
And because the user
profiles output changes,

62
00:04:24.139 --> 00:04:28.224
the input to the recommender
system now changes and

63
00:04:28.224 --> 00:04:33.740
this might affect the quality
of the product recommendations.

64
00:04:33.740 --> 00:04:37.139
When you have a machine
learning pipelines,

65
00:04:37.139 --> 00:04:42.602
these cascading effects in the pipeline
can be complex to keep track of.

66
00:04:42.602 --> 00:04:48.001
But if the percentage of unknown labels
does go up, this could be something that

67
00:04:48.001 --> 00:04:53.482
you want to be alerted to so that you can
update the recommender system if needed to

68
00:04:53.482 --> 00:04:58.670
make sure you continue to generate
high quality product recommendations.

69
00:04:58.670 --> 00:05:02.556
So when building these complex
machine learning pipelines,

70
00:05:02.556 --> 00:05:05.845
which can have machine
learning based components or

71
00:05:05.845 --> 00:05:10.031
non machine learning based
components throughout the pipeline,

72
00:05:10.031 --> 00:05:15.260
I find it useful to brainstorm metrics to
monitor that can detect changes including

73
00:05:15.260 --> 00:05:20.300
concept drift, all data driven or both,
and multiple stages of the pipeline.

74
00:05:20.300 --> 00:05:23.732
So metrics to monitor
include software metrics, for

75
00:05:23.732 --> 00:05:27.774
perhaps each of the components
in the pipeline, or perhaps for

76
00:05:27.774 --> 00:05:31.662
the overall pipeline as a whole,
as well as input metrics and

77
00:05:31.662 --> 00:05:36.350
potentially output metrics for
each of the components of the pipeline.

78
00:05:36.350 --> 00:05:41.093
And by brainstorming metrics associated
with individual components of

79
00:05:41.093 --> 00:05:45.834
the pipeline as well, this could help
you spot problems such as the voice

80
00:05:45.834 --> 00:05:51.133
activity detection system of putting
longer or shorter audio clears over time.

81
00:05:51.133 --> 00:05:56.621
Or the user profile system suddenly
having more unknown attributes for

82
00:05:56.621 --> 00:06:01.283
whether the user owns a car and
thereby alert you to changes in

83
00:06:01.283 --> 00:06:06.430
the data that may require you to
take action to maintain the model.

84
00:06:06.430 --> 00:06:11.260
But the principle that you saw in the last
video of brainstorm all the things

85
00:06:11.260 --> 00:06:16.089
that could go wrong, including things
that could go wrong with individual

86
00:06:16.089 --> 00:06:20.180
components of the pipeline and
design metrics to track those.

87
00:06:20.180 --> 00:06:24.532
That principle still applies only now
you're looking at multiple components in

88
00:06:24.532 --> 00:06:25.380
the pipeline.

89
00:06:25.380 --> 00:06:28.980
Finally, how quickly does data change?

90
00:06:28.980 --> 00:06:33.907
The rate at which data changes is
very problem dependent, for example,

91
00:06:33.907 --> 00:06:38.752
let's say you built to face recognition
system, then the rate at which

92
00:06:38.752 --> 00:06:42.815
people's appearances changes
usually isn't that fast.

93
00:06:42.815 --> 00:06:47.792
People's hairstyles and clothing does
change with fashion changes and as cameras

94
00:06:47.792 --> 00:06:52.699
get better, we've been getting higher and
higher resolution pictures of people

95
00:06:52.699 --> 00:06:58.240
over time, but for the most part, people's
appearances don't change that much.

96
00:06:58.240 --> 00:07:01.836
But there are sometimes things that
can change very quickly as well,

97
00:07:01.836 --> 00:07:05.928
such as if a factory gets a new batch of
material for how they make cell phones and

98
00:07:05.928 --> 00:07:08.740
so all the cell phones start
to change in appearance.

99
00:07:08.740 --> 00:07:13.395
So some applications will have data that
changes over the time scale of months or

100
00:07:13.395 --> 00:07:14.228
even years and

101
00:07:14.228 --> 00:07:19.040
some applications with data that could
suddenly change in a matter of minutes.

102
00:07:19.040 --> 00:07:21.960
Speaking in very broad generalities,

103
00:07:21.960 --> 00:07:27.280
I find that on average user data
generally changes relatively slowly.

104
00:07:27.280 --> 00:07:32.318
If you run a consumer facing business
with a very large numbers of users,

105
00:07:32.318 --> 00:07:33.969
then it is quite rare for

106
00:07:33.969 --> 00:07:39.540
millions of users to all suddenly change
their behavior all at the same time.

107
00:07:39.540 --> 00:07:43.101
And so user data,
if you've a large number of users,

108
00:07:43.101 --> 00:07:45.890
will usually change relatively slowly.

109
00:07:45.890 --> 00:07:48.185
There are a few exceptions, of course,

110
00:07:48.185 --> 00:07:52.507
COVID-19 being one of them where a shock
to society actually cause a lot of

111
00:07:52.507 --> 00:07:55.940
people's behavior that all
change at the same time.

112
00:07:55.940 --> 00:08:00.441
And if you look at web search traffic,
you will see trends, maybe a holiday or

113
00:08:00.441 --> 00:08:05.310
a new movie and people start searching for
something new that just became popular.

114
00:08:05.310 --> 00:08:09.983
So there are exceptions, but on average,
if you have a very large group of users,

115
00:08:09.983 --> 00:08:14.186
there are only a few forces that can
simultaneously change the behavior of

116
00:08:14.186 --> 00:08:16.640
a lot of people all at the same time.

117
00:08:16.640 --> 00:08:21.530
In contrast, if you work on a B2B or
business to business application,

118
00:08:21.530 --> 00:08:26.501
I find it enterprise data or business
data can shift quite quickly because

119
00:08:26.501 --> 00:08:31.469
the factory making cellphones may
suddenly decide to use a new coating for

120
00:08:31.469 --> 00:08:35.958
their cell phones and suddenly
the entire data set changes because

121
00:08:35.958 --> 00:08:39.120
the cell phones suddenly
all look different.

122
00:08:39.120 --> 00:08:43.764
But if you're providing a machine
learning system to a company,

123
00:08:43.764 --> 00:08:48.746
then sometimes if the CEO of that
company decides to change the way that

124
00:08:48.746 --> 00:08:53.540
business operates,
all of that data can shift very quickly.

125
00:08:53.540 --> 00:08:58.023
I know that these two bullets
are me speaking in generalities and

126
00:08:58.023 --> 00:09:03.253
there are certain exceptions to both
of these, but maybe this will give you

127
00:09:03.253 --> 00:09:09.140
a way of thinking about how quickly your
data is likely to change or not change.

128
00:09:09.140 --> 00:09:10.120
So that's it.

129
00:09:10.120 --> 00:09:14.940
Congratulations on making it to
the end of this first weeks videos.

130
00:09:14.940 --> 00:09:18.420
I hope you also take a look at
the practice quizzes, which will let you

131
00:09:18.420 --> 00:09:22.160
practice all of these concepts and
make sure you deeply understand them.

132
00:09:22.160 --> 00:09:23.078
And if you want,

133
00:09:23.078 --> 00:09:27.537
you can also take a look at this week's
optional programming exercise which will

134
00:09:27.537 --> 00:09:31.540
let you deploy a machine learning
model on your own computer.

135
00:09:31.540 --> 00:09:35.459
And I also look forward to seeing you
in next week's videos where we'll

136
00:09:35.459 --> 00:09:39.900
dive together much more deeply into the
modeling part of the full cycle of machine

137
00:09:39.900 --> 00:09:41.040
learning project.

138
00:09:41.040 --> 00:09:42.761
I look forward to seeing you next week.