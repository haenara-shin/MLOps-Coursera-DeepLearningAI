WEBVTT

1
00:00:00.000 --> 00:00:02.190
Data sets where the ratio of

2
00:00:02.190 --> 00:00:04.049
positive to negative examples

3
00:00:04.049 --> 00:00:08.165
is very far from 50-50 are
called skewed data sets.

4
00:00:08.165 --> 00:00:11.655
Let's look at some special
techniques for handling them.

5
00:00:11.655 --> 00:00:14.265
Let me start with a
manufacturing example.

6
00:00:14.265 --> 00:00:18.540
If a manufacturing company
makes smartphones,

7
00:00:18.540 --> 00:00:22.740
hopefully, the vast majority
of them are not defective.

8
00:00:22.740 --> 00:00:27.165
If 99.7 percent have no
defect and are labeled

9
00:00:27.165 --> 00:00:29.085
y equals 0 and

10
00:00:29.085 --> 00:00:32.760
only a small fraction
is labeled y equals 1,

11
00:00:32.760 --> 00:00:36.705
then print 0,

12
00:00:36.705 --> 00:00:39.810
which is not a very impressive
learning algorithm.

13
00:00:39.810 --> 00:00:43.595
We achieve 99.7 percent accuracy.

14
00:00:43.595 --> 00:00:46.120
For medical diagnosis, which was

15
00:00:46.120 --> 00:00:49.375
the example we went through
in an earlier video,

16
00:00:49.375 --> 00:00:52.340
if 99 percent of patients
don't have a disease,

17
00:00:52.340 --> 00:00:56.290
then an algorithm that predicts
no one ever has a disease

18
00:00:56.290 --> 00:01:00.845
will have 99 percent accuracy
or speech recognition.

19
00:01:00.845 --> 00:01:04.389
If you're building a system
for wake word detection,

20
00:01:04.389 --> 00:01:06.730
sometimes also called
trigger word detection,

21
00:01:06.730 --> 00:01:10.060
these are systems that
listen and see if you say

22
00:01:10.060 --> 00:01:14.355
a special word like Alexa
or Okay Google or Hey Zoe,

23
00:01:14.355 --> 00:01:17.855
most of the time that special
wake word or trigger word

24
00:01:17.855 --> 00:01:21.585
is not being spoken by anyone
at that moment in time.

25
00:01:21.585 --> 00:01:24.875
When I had built wake
word detection systems,

26
00:01:24.875 --> 00:01:27.460
the data sets were actually quite
skewed. One of the data

27
00:01:27.460 --> 00:01:30.750
sets I used had 96.7

28
00:01:30.750 --> 00:01:32.700
percent negative examples and

29
00:01:32.700 --> 00:01:35.080
3.3 percent positive examples.

30
00:01:35.080 --> 00:01:38.320
When you have a very
skewed data set like this,

31
00:01:38.320 --> 00:01:42.580
low accuracy is not
that useful a metric to

32
00:01:42.580 --> 00:01:47.260
look at because print zero
can get very high accuracy.

33
00:01:47.260 --> 00:01:49.750
Instead, it's more useful to

34
00:01:49.750 --> 00:01:52.420
build something called
the confusion matrix.

35
00:01:52.420 --> 00:01:55.660
A confusion matrix
is a matrix where

36
00:01:55.660 --> 00:01:59.400
one axis is labeled
with the actual label,

37
00:01:59.400 --> 00:02:01.245
is the ground truth label,

38
00:02:01.245 --> 00:02:04.140
y equals 0 or y equals 1

39
00:02:04.140 --> 00:02:08.110
and whose other axis is
labeled with the prediction.

40
00:02:08.110 --> 00:02:10.944
Was your learning
algorithms prediction

41
00:02:10.944 --> 00:02:15.180
y equals 0 or y equals 1?

42
00:02:15.180 --> 00:02:18.720
If you're building
a confusion matrix,

43
00:02:18.720 --> 00:02:23.170
you fill in with each
of these four cells,

44
00:02:23.170 --> 00:02:24.570
the total number of

45
00:02:24.570 --> 00:02:26.940
examples say the
number of examples in

46
00:02:26.940 --> 00:02:28.830
your dev set in
your development

47
00:02:28.830 --> 00:02:32.285
set to fell into each
of these four buckets.

48
00:02:32.285 --> 00:02:38.460
Let's say that 905 examples
in your development set had

49
00:02:38.460 --> 00:02:40.755
a drought-proof
label of y equals 0

50
00:02:40.755 --> 00:02:44.295
and then you might
write 905 there.

51
00:02:44.295 --> 00:02:46.020
These examples are called

52
00:02:46.020 --> 00:02:48.360
true negatives because they were

53
00:02:48.360 --> 00:02:51.090
actually negative
and your algorithm

54
00:02:51.090 --> 00:02:52.500
predicted they was negative.

55
00:02:52.500 --> 00:02:55.740
Next, lets fill in
the true positives,

56
00:02:55.740 --> 00:02:57.965
which are the examples where
the actual structure of

57
00:02:57.965 --> 00:03:00.385
labels one and the
prediction is one,

58
00:03:00.385 --> 00:03:05.145
maybe there are 68 of
them, true positives.

59
00:03:05.145 --> 00:03:07.200
The false negatives are

60
00:03:07.200 --> 00:03:11.205
the examples where your
algorithm father was negative,

61
00:03:11.205 --> 00:03:13.350
but it was wrong.

62
00:03:13.350 --> 00:03:16.365
The actual label is positive,

63
00:03:16.365 --> 00:03:19.290
these are false negatives.

64
00:03:19.290 --> 00:03:21.895
The 18 of that and lastly,

65
00:03:21.895 --> 00:03:23.880
false positives
are the ones where

66
00:03:23.880 --> 00:03:25.920
your algorithm
father was positive,

67
00:03:25.920 --> 00:03:31.920
but that turned out to be
false, nine false positives.

68
00:03:31.920 --> 00:03:36.565
The precision of
learning algorithm,

69
00:03:36.565 --> 00:03:39.615
if I sum up over the columns,

70
00:03:39.615 --> 00:03:48.360
905 plus 9 is 914 and
18 plus 68 is 86.

71
00:03:48.360 --> 00:03:52.740
This is indeed a pretty
skewed data set where out of

72
00:03:52.740 --> 00:03:55.020
1000 examples there were

73
00:03:55.020 --> 00:04:00.495
940 negative examples and
just 86 positive examples,

74
00:04:00.495 --> 00:04:05.475
8.6 percent positive,
91.4 percent negative.

75
00:04:05.475 --> 00:04:10.840
The precision of your
learning algorithm

76
00:04:10.840 --> 00:04:12.730
is defined as follows,

77
00:04:12.730 --> 00:04:15.070
it asks of all the examples

78
00:04:15.070 --> 00:04:18.205
that the algorithm thought
were positive examples,

79
00:04:18.205 --> 00:04:21.005
what fraction did they get?

80
00:04:21.005 --> 00:04:26.355
Precision as is defined
as true positives

81
00:04:26.355 --> 00:04:31.935
divided by true positives
plus false positives.

82
00:04:31.935 --> 00:04:36.930
In other words, it
looks at this row.

83
00:04:36.930 --> 00:04:39.080
Of all the examples that

84
00:04:39.080 --> 00:04:41.165
your average thoughts
had a label of one,

85
00:04:41.165 --> 00:04:44.030
which is 68 plus 9 of them,

86
00:04:44.030 --> 00:04:46.610
68 of them were actually right.

87
00:04:46.610 --> 00:04:53.505
The precision is
68 over 68 plus 9,

88
00:04:53.505 --> 00:04:56.655
which is 88.3 percent.

89
00:04:56.655 --> 00:05:02.430
In contrast there we call
as of all the examples,

90
00:05:02.430 --> 00:05:05.310
there were actually positive,

91
00:05:05.310 --> 00:05:08.730
what fraction did your
algorithm get right?

92
00:05:08.730 --> 00:05:12.795
Recall is defined
as true positives

93
00:05:12.795 --> 00:05:17.250
divided by true positives
plus false negatives,

94
00:05:17.250 --> 00:05:22.859
which in this case is
68 over 68 plus 18,

95
00:05:22.859 --> 00:05:28.140
which is 79.1 percent.

96
00:05:28.140 --> 00:05:33.570
The metrics are precision and
recall are more useful than

97
00:05:33.570 --> 00:05:37.320
law accuracy when it
comes to evaluating

98
00:05:37.320 --> 00:05:39.180
the performance of
learning algorithms

99
00:05:39.180 --> 00:05:41.315
on very skewed data sets.

100
00:05:41.315 --> 00:05:43.230
Let's see what happens if

101
00:05:43.230 --> 00:05:46.635
your learning algorithm
outputs zero all the time.

102
00:05:46.635 --> 00:05:50.565
It turns out it won't
do very well on recall.

103
00:05:50.565 --> 00:05:53.175
Taking this example
of where we had

104
00:05:53.175 --> 00:05:57.824
914 negative examples and
86 positive examples,

105
00:05:57.824 --> 00:06:01.390
if the algorithm outputs
zero all the time.

106
00:06:01.390 --> 00:06:04.520
This is what the confusion
matrix will look like,

107
00:06:04.520 --> 00:06:08.525
914 times it'll output zero
with a grand total of zero,

108
00:06:08.525 --> 00:06:10.305
and 86 times it'll output

109
00:06:10.305 --> 00:06:12.810
zero with a ground truth of one.

110
00:06:12.810 --> 00:06:16.670
Precision is true
positives divided

111
00:06:16.670 --> 00:06:20.195
by true positives
plus false positives,

112
00:06:20.195 --> 00:06:22.730
which in this case
turns out to be zero

113
00:06:22.730 --> 00:06:26.825
over zero plus zero,

114
00:06:26.825 --> 00:06:28.890
which is not defined,

115
00:06:28.890 --> 00:06:30.845
and unless your
algorithm actually

116
00:06:30.845 --> 00:06:34.290
outputs no positive
labels at all,

117
00:06:34.290 --> 00:06:36.105
you get some of the number that

118
00:06:36.105 --> 00:06:38.130
hopefully isn't zero over zero.

119
00:06:38.130 --> 00:06:40.780
But more importantly,
if you look at recall,

120
00:06:40.780 --> 00:06:42.935
which is true positives over

121
00:06:42.935 --> 00:06:45.815
true positives plus
false negatives,

122
00:06:45.815 --> 00:06:53.975
this turns out to be
zero over zero plus 86,

123
00:06:53.975 --> 00:06:57.245
which is zero percent,

124
00:06:57.245 --> 00:07:03.050
and so the 0.0 algorithm
achieves zero percent recall,

125
00:07:03.050 --> 00:07:06.465
which gives you an easy way
to flag that this is not

126
00:07:06.465 --> 00:07:10.095
detecting any useful,
positive examples.

127
00:07:10.095 --> 00:07:12.785
The learning algorithm
with some precision,

128
00:07:12.785 --> 00:07:15.310
even the high value of
precision is not that

129
00:07:15.310 --> 00:07:19.250
useful usually if this
recall is so low.

130
00:07:19.250 --> 00:07:22.550
The standard metrics when
I look at when comparing

131
00:07:22.550 --> 00:07:24.855
different models on
skewed data sets

132
00:07:24.855 --> 00:07:27.600
are precision and recall.

133
00:07:27.600 --> 00:07:31.070
Where looking at these
numbers helps you figure out

134
00:07:31.070 --> 00:07:35.089
and of all the examples that
are truly positive examples,

135
00:07:35.089 --> 00:07:38.465
what fraction did the
algorithm manage to catch?

136
00:07:38.465 --> 00:07:40.970
Sometimes you have one model with

137
00:07:40.970 --> 00:07:43.610
a better recall and

138
00:07:43.610 --> 00:07:46.595
a different model with
a better precision.

139
00:07:46.595 --> 00:07:49.485
How do you compare
two different models?

140
00:07:49.485 --> 00:07:51.750
There's a common way of combining

141
00:07:51.750 --> 00:07:54.735
precision and recall
using this formula,

142
00:07:54.735 --> 00:07:57.065
which is called the F_1 score.

143
00:07:57.065 --> 00:08:01.460
One intuition behind
the F_1 score is

144
00:08:01.460 --> 00:08:03.770
that you want an algorithm to

145
00:08:03.770 --> 00:08:06.765
do well on both
precision and recall,

146
00:08:06.765 --> 00:08:08.655
and if it does worse on

147
00:08:08.655 --> 00:08:12.505
either precision or
recall, that's pretty bad.

148
00:08:12.505 --> 00:08:17.150
F_1 is a way of combining
precision and recall that

149
00:08:17.150 --> 00:08:19.725
emphasizes whichever of P or

150
00:08:19.725 --> 00:08:22.860
R precision or recall is worse.

151
00:08:22.860 --> 00:08:26.205
In mathematics, this is
technically called a

152
00:08:26.205 --> 00:08:29.780
harmonic mean between
precision and recall,

153
00:08:29.780 --> 00:08:31.990
which is like taking
the average but placing

154
00:08:31.990 --> 00:08:34.955
more emphasis on whichever
is the lower number.

155
00:08:34.955 --> 00:08:38.784
If you compute the F_1
score of these two models,

156
00:08:38.784 --> 00:08:41.025
it turns out to be

157
00:08:41.025 --> 00:08:45.365
83.4 percent using the
formula below here.

158
00:08:45.365 --> 00:08:48.255
Model 2 has a very bad recall,

159
00:08:48.255 --> 00:08:51.290
so its F_1 score is

160
00:08:51.290 --> 00:08:56.965
actually quite low as well
and this lets us tell,

161
00:08:56.965 --> 00:08:59.700
maybe more clearly
that Model 1

162
00:08:59.700 --> 00:09:03.215
appears to be a superior
model than Model 2.

163
00:09:03.215 --> 00:09:05.410
For your application,
you may have

164
00:09:05.410 --> 00:09:07.850
a different weighting
between position and recall,

165
00:09:07.850 --> 00:09:09.195
and so F_1 isn't

166
00:09:09.195 --> 00:09:11.640
the only way to combine
precision and recall,

167
00:09:11.640 --> 00:09:13.420
it's just one metric
that's commonly

168
00:09:13.420 --> 00:09:15.250
used for many applications.

169
00:09:15.250 --> 00:09:17.480
Let me step through
one more example where

170
00:09:17.480 --> 00:09:20.520
precision and recall is useful.

171
00:09:20.520 --> 00:09:21.910
So far, we've talked about

172
00:09:21.910 --> 00:09:25.350
the binary classification
problem with skewed data sets.

173
00:09:25.350 --> 00:09:28.250
It turns out to also
frequently be useful

174
00:09:28.250 --> 00:09:31.255
for multi-class
classification problems.

175
00:09:31.255 --> 00:09:34.665
If you are detecting
defects in smartphones,

176
00:09:34.665 --> 00:09:37.130
you may want to
detect scratches on

177
00:09:37.130 --> 00:09:39.680
them or dents or pit marks.

178
00:09:39.680 --> 00:09:41.780
This is what it looks
like if someone

179
00:09:41.780 --> 00:09:44.500
took a screwdriver and
poked their cell phone,

180
00:09:44.500 --> 00:09:46.500
or discoloration of

181
00:09:46.500 --> 00:09:49.930
the cell phone's LCD
screen or other material.

182
00:09:49.930 --> 00:09:53.395
Maybe all four of these defects
are actually quite rare

183
00:09:53.395 --> 00:09:55.220
that you might want to develop

184
00:09:55.220 --> 00:09:57.655
an algorithm that can
detect all four of them.

185
00:09:57.655 --> 00:10:00.400
One way to evaluate
how your algorithm is

186
00:10:00.400 --> 00:10:03.450
doing on all four
of these defects,

187
00:10:03.450 --> 00:10:06.110
each of which can be quite rare,

188
00:10:06.110 --> 00:10:09.105
would be to look at precision
and recall of each of

189
00:10:09.105 --> 00:10:12.345
these four types of
defects individually.

190
00:10:12.345 --> 00:10:16.310
In this example, the
learning algorithm has 82.1

191
00:10:16.310 --> 00:10:17.840
percent precision on finding

192
00:10:17.840 --> 00:10:20.685
scratches and 99.2
percent recall.

193
00:10:20.685 --> 00:10:22.835
You find in manufacturing that

194
00:10:22.835 --> 00:10:25.510
many factories will
want high recall

195
00:10:25.510 --> 00:10:27.860
because you really
don't want to let

196
00:10:27.860 --> 00:10:30.765
the phone go out
that is defective.

197
00:10:30.765 --> 00:10:31.965
But if an algorithm has

198
00:10:31.965 --> 00:10:33.870
slightly lower
precision, that's okay,

199
00:10:33.870 --> 00:10:38.570
because through a human
re-examining the phone,

200
00:10:38.570 --> 00:10:40.070
they will hopefully figure

201
00:10:40.070 --> 00:10:41.750
out that the phone
is actually okay,

202
00:10:41.750 --> 00:10:45.830
so many factories will
emphasize high recall.

203
00:10:45.830 --> 00:10:51.275
By combining precision and
recall using F_1 as follows,

204
00:10:51.275 --> 00:10:55.340
this gives you a single number
evaluation metric for how

205
00:10:55.340 --> 00:10:56.880
well your algorithm is doing

206
00:10:56.880 --> 00:10:59.220
on the four different types of

207
00:10:59.220 --> 00:11:02.680
defects and can also
help you benchmark to

208
00:11:02.680 --> 00:11:04.845
human-level performance and also

209
00:11:04.845 --> 00:11:07.610
prioritize what to work on next.

210
00:11:07.610 --> 00:11:10.220
Instead of accuracy on scratches,

211
00:11:10.220 --> 00:11:12.465
dents, pit marks,
and discolorations,

212
00:11:12.465 --> 00:11:15.710
using F_1 score can help you to

213
00:11:15.710 --> 00:11:19.190
prioritize the most fruitful type

214
00:11:19.190 --> 00:11:21.800
of defect to try to work on.

215
00:11:21.800 --> 00:11:25.265
The reason we use F_1 is because,

216
00:11:25.265 --> 00:11:30.125
maybe all four defects are
very rare and so accuracy

217
00:11:30.125 --> 00:11:32.620
would be very high even if

218
00:11:32.620 --> 00:11:36.030
the algorithm was missing
a lot of these defects.

219
00:11:36.030 --> 00:11:39.825
I hope that these tools
will help you both evaluate

220
00:11:39.825 --> 00:11:43.175
your algorithm as well as
prioritize what to work on,

221
00:11:43.175 --> 00:11:46.375
both in problems with
skewed data sets and

222
00:11:46.375 --> 00:11:50.030
for problems with
multiple rare classes.

223
00:11:50.030 --> 00:11:53.594
Now, to wrap up the
section on Error Analysis,

224
00:11:53.594 --> 00:11:57.055
there's one final concept I
hope to go over with you,

225
00:11:57.055 --> 00:11:59.150
which is Performance Auditing.

226
00:11:59.150 --> 00:12:03.435
I found for many projects this
is a key step to make sure

227
00:12:03.435 --> 00:12:05.785
the learning algorithm
is working well enough

228
00:12:05.785 --> 00:12:08.830
before you push it out to
a production deployment.

229
00:12:08.830 --> 00:12:12.230
Let's take a look at
Performance Auditing.