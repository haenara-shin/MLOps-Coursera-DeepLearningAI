WEBVTT

1
00:00:00.000 --> 00:00:02.725
Let me share with
you a few tips for

2
00:00:02.725 --> 00:00:05.320
getting started on
machine learning project.

3
00:00:05.320 --> 00:00:07.360
This video will be
a little bit of

4
00:00:07.360 --> 00:00:09.310
a grab bag of different ideas,

5
00:00:09.310 --> 00:00:10.885
but I hope nonetheless

6
00:00:10.885 --> 00:00:13.015
many of these ideas
will be useful to you.

7
00:00:13.015 --> 00:00:15.580
We've talked about how
machine learning is

8
00:00:15.580 --> 00:00:17.625
an iterative process
where you start with

9
00:00:17.625 --> 00:00:20.440
a model, data, hyperparameters,

10
00:00:20.440 --> 00:00:24.910
training model, carry
out error analysis,

11
00:00:24.910 --> 00:00:28.860
and then use that to drive
further improvements.

12
00:00:28.860 --> 00:00:30.940
After you've done
this a few times,

13
00:00:30.940 --> 00:00:32.590
gone around the
loop enough times,

14
00:00:32.590 --> 00:00:34.855
when you have a
good enough model,

15
00:00:34.855 --> 00:00:36.220
you might then carry out

16
00:00:36.220 --> 00:00:40.550
a final performance audit
before taking it to production.

17
00:00:40.550 --> 00:00:42.670
In order to get started on

18
00:00:42.670 --> 00:00:46.339
this first step of
coming of the model,

19
00:00:46.339 --> 00:00:48.160
here are some suggestions.

20
00:00:48.160 --> 00:00:50.830
When I'm starting on a
machine learning project,

21
00:00:50.830 --> 00:00:52.780
I almost always start with

22
00:00:52.780 --> 00:00:55.430
a quick literature search
to see what's possible,

23
00:00:55.430 --> 00:00:57.460
so you can look at
online courses,

24
00:00:57.460 --> 00:01:01.055
look at blogs, look at
open source projects.

25
00:01:01.055 --> 00:01:05.260
My advice to you
if your goal is to

26
00:01:05.260 --> 00:01:07.570
build a practical
production system

27
00:01:07.570 --> 00:01:09.715
and not to do research is,

28
00:01:09.715 --> 00:01:11.410
don't obsess about finding

29
00:01:11.410 --> 00:01:14.290
the latest, greatest algorithm.

30
00:01:14.290 --> 00:01:16.750
Instead, spend half a day,

31
00:01:16.750 --> 00:01:21.010
maybe a small number of days
reading blog posts and pick

32
00:01:21.010 --> 00:01:25.484
something reasonable that
lets you get started quickly,

33
00:01:25.484 --> 00:01:28.185
if you can find an open
source implementation,

34
00:01:28.185 --> 00:01:30.280
that can also help you establish

35
00:01:30.280 --> 00:01:32.505
a baseline more efficiently.

36
00:01:32.505 --> 00:01:36.430
I find that for many
practical applications,

37
00:01:36.430 --> 00:01:41.170
a reasonable algorithm with
good data will often do

38
00:01:41.170 --> 00:01:43.360
just fine and will
in fact outperform

39
00:01:43.360 --> 00:01:46.725
a great algorithm with
not so good data.

40
00:01:46.725 --> 00:01:50.080
Don't obsess about taking
the algorithm that was just

41
00:01:50.080 --> 00:01:53.290
published in some
conference last week,

42
00:01:53.290 --> 00:01:55.495
that is the most
cutting edge algorithm,

43
00:01:55.495 --> 00:01:57.445
instead find
something reasonable,

44
00:01:57.445 --> 00:01:59.890
find a good open
source implementation

45
00:01:59.890 --> 00:02:02.715
and use that to
get going quickly.

46
00:02:02.715 --> 00:02:04.600
Because being able to get

47
00:02:04.600 --> 00:02:08.915
started on this first
step of this loop,

48
00:02:08.915 --> 00:02:11.000
can make you more efficient in

49
00:02:11.000 --> 00:02:13.430
iterating through more times,

50
00:02:13.430 --> 00:02:15.320
and that will help you get

51
00:02:15.320 --> 00:02:17.780
to good performance more quickly.

52
00:02:17.780 --> 00:02:21.940
Second question I have often been asked
, is, "Hey Andrew,

53
00:02:21.940 --> 00:02:25.459
do I need to take into account
deployment constraints

54
00:02:25.459 --> 00:02:29.000
such as compute constraints
when picking a model?"

55
00:02:29.000 --> 00:02:31.535
My answer is, yes you should take

56
00:02:31.535 --> 00:02:33.050
deployment constraints such as

57
00:02:33.050 --> 00:02:34.580
compute constraints into account,

58
00:02:34.580 --> 00:02:36.350
if the baseline is already

59
00:02:36.350 --> 00:02:39.410
established and you're
relatively confident

60
00:02:39.410 --> 00:02:41.475
that this project
will work and thus

61
00:02:41.475 --> 00:02:44.895
your goal is to build
and deploy a system.

62
00:02:44.895 --> 00:02:47.975
But if you have not yet even
established a baseline,

63
00:02:47.975 --> 00:02:50.240
or if you're not yet
sure if this project

64
00:02:50.240 --> 00:02:52.805
will work and be
worthy of deployment,

65
00:02:52.805 --> 00:02:54.320
then I will say no,

66
00:02:54.320 --> 00:02:55.700
or maybe not necessarily.

67
00:02:55.700 --> 00:02:57.800
If you are in a stage of

68
00:02:57.800 --> 00:03:00.680
the project where your first
goal is to just establish

69
00:03:00.680 --> 00:03:03.890
a baseline and determine
what is possible and if

70
00:03:03.890 --> 00:03:07.295
this project is even worth
pursuing for the long term,

71
00:03:07.295 --> 00:03:09.410
then it might be okay to ignore

72
00:03:09.410 --> 00:03:11.780
deployment constraints
and just find

73
00:03:11.780 --> 00:03:14.300
some open source
implementation and

74
00:03:14.300 --> 00:03:17.045
try it out to see what
might be possible,

75
00:03:17.045 --> 00:03:20.060
even if that open source
implementation is so

76
00:03:20.060 --> 00:03:22.130
computationally
intensive that you know

77
00:03:22.130 --> 00:03:24.620
you will never be
able to deploy that.

78
00:03:24.620 --> 00:03:26.600
Of course, no harm taking

79
00:03:26.600 --> 00:03:28.640
deployment constraints
into account as

80
00:03:28.640 --> 00:03:30.980
well at this phase
of the project,

81
00:03:30.980 --> 00:03:35.105
but it might also be
okay if you don't

82
00:03:35.105 --> 00:03:37.040
and focus on more

83
00:03:37.040 --> 00:03:40.070
efficiently establishing
the baseline first.

84
00:03:40.070 --> 00:03:42.350
Finally, when trying out

85
00:03:42.350 --> 00:03:44.585
a learning algorithm
for the first time,

86
00:03:44.585 --> 00:03:47.345
before running it
on all your data,

87
00:03:47.345 --> 00:03:48.830
I would urge you to run

88
00:03:48.830 --> 00:03:50.600
a few quick sanity checks

89
00:03:50.600 --> 00:03:52.795
for your code and your algorithm.

90
00:03:52.795 --> 00:03:56.090
For example, I will
usually try to

91
00:03:56.090 --> 00:03:59.270
overfit a very small
training dataset

92
00:03:59.270 --> 00:04:02.300
before spending hours
or sometimes even

93
00:04:02.300 --> 00:04:03.860
overnight or days training

94
00:04:03.860 --> 00:04:06.020
the algorithm on a large dataset.

95
00:04:06.020 --> 00:04:08.570
Maybe even try to
make sure you can

96
00:04:08.570 --> 00:04:11.000
fit one training example,

97
00:04:11.000 --> 00:04:14.045
especially, if the output
is a complex output.

98
00:04:14.045 --> 00:04:15.770
For example, I was once

99
00:04:15.770 --> 00:04:17.990
working on a speech
recognition system

100
00:04:17.990 --> 00:04:20.090
where the goal was
to input audio and

101
00:04:20.090 --> 00:04:22.220
have a learning algorithm
output a transcript.

102
00:04:22.220 --> 00:04:24.350
When I trained my algorithm on

103
00:04:24.350 --> 00:04:26.825
just one example, one audio clip,

104
00:04:26.825 --> 00:04:29.660
when I trained my speech
recognition system on

105
00:04:29.660 --> 00:04:32.480
just one audio clip
on the training set,

106
00:04:32.480 --> 00:04:34.205
which is just one audio clip,

107
00:04:34.205 --> 00:04:35.760
my system outputs this,

108
00:04:35.760 --> 00:04:37.160
it outputs space, space,

109
00:04:37.160 --> 00:04:38.720
space, space, space, space.

110
00:04:38.720 --> 00:04:42.200
Clearly it wasn't working
and because my speech system

111
00:04:42.200 --> 00:04:46.310
couldn't even accurately
transcribe one training example,

112
00:04:46.310 --> 00:04:48.710
there wasn't much
point to spending

113
00:04:48.710 --> 00:04:51.725
hours and hours training it
on a giant training set.

114
00:04:51.725 --> 00:04:53.840
Or for image segmentation,

115
00:04:53.840 --> 00:04:57.500
if your goal is to take
as input pictures like

116
00:04:57.500 --> 00:05:01.270
this and segment out
the cats in the image,

117
00:05:01.270 --> 00:05:04.370
then before spending
hours training

118
00:05:04.370 --> 00:05:08.119
your system on hundreds
or thousands of images,

119
00:05:08.119 --> 00:05:10.735
a worthy sanity check would be to

120
00:05:10.735 --> 00:05:14.100
feed it just one image
and see if it can

121
00:05:14.100 --> 00:05:17.569
at least overfit that
one training example

122
00:05:17.569 --> 00:05:20.745
before scaling up to
a larger dataset.

123
00:05:20.745 --> 00:05:22.820
The advantage of this is

124
00:05:22.820 --> 00:05:25.100
you may be able to
train your algorithm on

125
00:05:25.100 --> 00:05:27.590
one or a small handful
of examples in

126
00:05:27.590 --> 00:05:30.610
just minutes or
maybe even seconds

127
00:05:30.610 --> 00:05:33.830
and this lets you find
bugs much more quickly.

128
00:05:33.830 --> 00:05:37.020
Finally, for image
classification problems,

129
00:05:37.020 --> 00:05:39.960
even if you have 10,000

130
00:05:39.960 --> 00:05:42.110
images or 100,000 images

131
00:05:42.110 --> 00:05:44.300
or a million images
in your training set,

132
00:05:44.300 --> 00:05:46.220
it might be worthwhile to very

133
00:05:46.220 --> 00:05:48.290
quickly train your algorithm on

134
00:05:48.290 --> 00:05:52.100
a small subset of just
10 or maybe 100 images,

135
00:05:52.100 --> 00:05:53.660
because you can do that quickly.

136
00:05:53.660 --> 00:05:57.830
If your algorithm can't even
do well on 100 images, well,

137
00:05:57.830 --> 00:06:01.025
then it's clearly not going
to do well on 10,000 images,

138
00:06:01.025 --> 00:06:02.780
so this would be another useful

139
00:06:02.780 --> 00:06:04.820
sanity check for your code.

140
00:06:04.820 --> 00:06:08.180
Now, after you've trained
a machine learning model,

141
00:06:08.180 --> 00:06:09.920
after you've trained
your first model,

142
00:06:09.920 --> 00:06:11.960
one of the most
important things is,

143
00:06:11.960 --> 00:06:15.080
how do you carry out error
analysis to help you

144
00:06:15.080 --> 00:06:18.830
decide how to improve the
performance of your algorithm?

145
00:06:18.830 --> 00:06:20.990
Let's go on to the
next video to dive

146
00:06:20.990 --> 00:06:25.140
into error analysis and
performance auditing.